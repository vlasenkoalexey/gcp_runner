{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kubernetes_runner.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code_test.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import IPython.core\n",
    "import json\n",
    "import os.path\n",
    "import re\n",
    "import ipykernel\n",
    "import requests\n",
    "\n",
    "# Alternative that works for both Python 2 and 3:\n",
    "from requests.compat import urljoin\n",
    "\n",
    "try:  # Python 3 (see Edit2 below for why this may not work in Python 2)\n",
    "    from notebook.notebookapp import list_running_servers\n",
    "except ImportError:  # Python 2\n",
    "    import warnings\n",
    "    from IPython.utils.shimmodule import ShimWarning\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=ShimWarning)\n",
    "        from IPython.html.notebookapp import list_running_servers\n",
    "\n",
    "\n",
    "def get_notebook_path():\n",
    "    \"\"\"\n",
    "    Return the full path of the jupyter notebook.\n",
    "    !!! Doesn't work from VS code.\n",
    "    \"\"\"\n",
    "    kernel_id = re.search('kernel-(.*).json',\n",
    "                          ipykernel.connect.get_connection_file()).group(1)\n",
    "    servers = list_running_servers()\n",
    "    for ss in servers:\n",
    "        try:\n",
    "            response = requests.get(urljoin(ss['url'], 'api/sessions'),\n",
    "                                    params={'token': ss.get('token', '')}, timeout=1)\n",
    "            for nn in json.loads(response.text):\n",
    "                if nn['kernel']['id'] == kernel_id:\n",
    "                    relative_path = nn['notebook']['path']\n",
    "                    return os.path.join(ss['notebook_dir'], relative_path)\n",
    "        except Exception as e:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alekseyv/vlasenkoalexey/gcp_runner/00_core.ipynb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "get_notebook_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import nbdev.export\n",
    "import nbdev.imports\n",
    "import nbformat\n",
    "\n",
    "from gcp_runner.core import get_notebook_path\n",
    "\n",
    "if nbdev.imports.in_colab():\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "def read_colab_nb(notebook_path):\n",
    "    gdrive_file_id = re.search('/fileId=(.+)', notebook_path)[1]\n",
    "    # Authenticate and create the PyDrive client.\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    gdrive = GoogleDrive(gauth)\n",
    "    downloaded = gdrive.CreateFile({'id': gdrive_file_id})\n",
    "    downloaded_string = downloaded.GetContentString()\n",
    "    return nbformat.reads(downloaded_string, as_version=4)\n",
    "\n",
    "def find_default_export_for_notebook(notebook_path):\n",
    "    nb = read_colab_nb(notebook_path) \\\n",
    "        if nbdev.imports.in_colab() else nbdev.export.read_nb(notebook_path)\n",
    "    default = nbdev.export.find_default_export(nb['cells'])\n",
    "    return default\n",
    "\n",
    "def get_module_name():\n",
    "    return find_default_export_for_notebook(get_notebook_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "get_module_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pkgutil\n",
    "import importlib\n",
    "import time\n",
    "import nbdev.imports\n",
    "from nbdev.export import *\n",
    "\n",
    "def get_package_name():\n",
    "    \"Returns name of the current package\"\n",
    "    # see logic in https://github.com/fastai/nbdev/blob/master/nbdev/export.py\n",
    "    return str(nbdev.imports.Config().lib_path).split('/')[-1]\n",
    "\n",
    "def reload_package_modules(package_name):\n",
    "    \"Dynamically reloads package `package_name`.\"\n",
    "    # Reload order matters. First we need to reload all modules except \n",
    "    # the current one, and then reload current one. Otherwise reload might\n",
    "    # fail if current module refers to other module that has new functions added.\n",
    "    current_module_name = get_module_name()\n",
    "    current_module = None\n",
    "    for _, module_name, _ in (pkgutil.iter_modules([package_name])):\n",
    "        if current_module_name == module_name:\n",
    "            current_module\n",
    "        else:\n",
    "            module = importlib.import_module(package_name + '.' + module_name)\n",
    "            importlib.reload(module)\n",
    "    if current_module is not None:\n",
    "        importlib.reload(current_module)\n",
    "        \n",
    "def export_and_reload_all(silent=False, ignore_errors=False):\n",
    "    \"Converts all notebooks to modules, and reloads all modules\"\n",
    "    if nbdev.imports.in_ipython():\n",
    "        notebook2script(silent=silent)\n",
    "        # Need to reload packages in order\n",
    "        # Looks like when it is called with to_dict, it doesn't actually update files.\n",
    "        module_name_dict = notebook2script(silent=True, to_dict=True)\n",
    "        time.sleep(1)\n",
    "        #reload_package_modules(get_package_name())\n",
    "        module_name_to_notebook_path = \\\n",
    "            list ((key,str(value[0][1])) for key, value in module_name_dict.items())\n",
    "        sorted_list = sorted(module_name_to_notebook_path, key=lambda pair:pair[1])\n",
    "        package_name = get_package_name()\n",
    "        for (module_name, _) in sorted_list:\n",
    "            if ignore_errors:\n",
    "                try:\n",
    "                    module = importlib.import_module(package_name + '.' + module_name)\n",
    "                    importlib.reload(module)\n",
    "                except Error as e:\n",
    "                    print (e)\n",
    "            else:\n",
    "                module = importlib.import_module(package_name + '.' + module_name)\n",
    "                importlib.reload(module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kubernetes_runner.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code_test.ipynb.\n"
     ]
    }
   ],
   "source": [
    "export_and_reload_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import io\n",
    "\n",
    "from threading import Thread\n",
    "from queue import Queue \n",
    "\n",
    "def _reader(pipe, queue, pipe_name):\n",
    "    try:\n",
    "        with pipe:\n",
    "            for line in iter(pipe.readline, ''):\n",
    "                queue.put((pipe_name, line))\n",
    "    finally:\n",
    "        queue.put(None)\n",
    "        \n",
    "def run_process(args, **kwargs):\n",
    "    proc = subprocess.Popen(\n",
    "        args, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE, \n",
    "        bufsize=1,\n",
    "        encoding='utf-8')\n",
    "    \n",
    "    q = Queue()\n",
    "    Thread(target=_reader, args=[proc.stdout, q, 'stdout']).start()\n",
    "    Thread(target=_reader, args=[proc.stderr, q, 'stderr']).start()\n",
    "    for source, line in iter(q.get, None):\n",
    "        line = line.rstrip('\\n').rstrip('\\r')\n",
    "        if line != '':\n",
    "            if source == 'stderr':\n",
    "                print(\"\\x1b[31m{}\\x1b[0m\".format(line))\n",
    "            else:\n",
    "                print(line)\n",
    "    \n",
    "    return proc.poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_run_args(func, **kwargs):\n",
    "    package_name = get_package_name()\n",
    "    module_name = get_module_name()\n",
    "    function_name = func.__name__\n",
    "    args = ['--module-name=%s' % package_name + '.' + module_name,\n",
    "         '--function-name=%s' % function_name]\n",
    "    if kwargs is not None:\n",
    "        for key,value in kwargs.items():\n",
    "            args.append('--%s=%s' % (key.replace('_', '-'), str(value)))\n",
    "    \n",
    "    return args\n",
    "\n",
    "def get_run_python_args(func, python_binary='python', **kwargs):\n",
    "    args = [python_binary, \n",
    "         '-u',\n",
    "         '-m',\n",
    "         'gcp_runner.entry_point']\n",
    "    \n",
    "    args.extend(get_run_args(func, **kwargs))\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--module-name=gcp_runner.core', '--function-name=get_run_args']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run_args(get_run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kubernetes_runner.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code_test.ipynb.\n"
     ]
    }
   ],
   "source": [
    "export_and_reload_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_and_push_docker_image(docker_file_path, image_uri, push_docker=True, dry_run=False):\n",
    "    build_docker_args = ['docker', 'build', '-f', docker_file_path, '-t', image_uri, './']\n",
    "    print('Building Docker image:')\n",
    "    print(' '.join(build_docker_args))\n",
    "    if not dry_run:\n",
    "        result = run_process(build_docker_args)\n",
    "        if result:\n",
    "            return result\n",
    "    if push_docker:\n",
    "        push_docker_args = ['docker', 'push', image_uri]\n",
    "        print('Pushing Docker image:')\n",
    "        print(' '.join(push_docker_args))\n",
    "        if not dry_run:\n",
    "            result = run_process(push_docker_args)\n",
    "            if result:\n",
    "                return result\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_20200409_154904_alekseyv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "import datetime\n",
    "import getpass\n",
    "\n",
    "def format_job_dir(job_dir, date_time:datetime.datetime=None):\n",
    "    if date_time is None:\n",
    "        date_time = datetime.datetime.now()\n",
    "    return job_dir.format(**{'datetime':datetime.datetime.now().strftime('%Y%m%d_%H%M%S'), 'username': getpass.getuser()})\n",
    "\n",
    "format_job_dir('model_{datetime}_{username}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def print_tensorboard_command(job_dir):\n",
    "    print('To see job output in tensorboard, run following command:')\n",
    "    print('tensorboard --logdir=%s' % job_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alekseyv-scalableai-dev\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def setup_service_account(user_name=None, project_name=None, service_account_key_file_path='./service_account.json'):\n",
    "    if project_name is None:\n",
    "        project_name = run_process('gcloud config get-value project --quiet'.split(' '))\n",
    "        if project_name is None or project_name == '':\n",
    "            print('gcloud project is not configured, please set it up first by running:'\n",
    "                 ' gcloud config set project <PROJECT_NAME>')\n",
    "            return -1\n",
    "    if user_name is None:\n",
    "        if nbdev.imports.in_colab():\n",
    "            from google.colab import auth\n",
    "            auth.authenticate_user()\n",
    "            user_name = run_process('gcloud config get-value account --quiet'.split(' '))\n",
    "            if user_name is None or user_name == '':\n",
    "                print(\"can't identify user name, please specify it explicitly\")\n",
    "                return -1\n",
    "            if '@' in user_name:\n",
    "                user_name = user_name[:user_name.index('@')]\n",
    "        else:\n",
    "            user_name = os.environ['USER']\n",
    "            if user_name is None or user_name == '':\n",
    "                print(\"can't identify user name, please specify it explicitly\")\n",
    "                return -1\n",
    "    \n",
    "setup_service_account()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alekseyv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alekseyv-scalableai-dev\n"
     ]
    }
   ],
   "source": [
    "! gcloud config get-value project --quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit7b4457a69e3f428895ab4777589eb494"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
