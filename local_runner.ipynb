{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp local_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import IPython.core\n",
    "import json\n",
    "import os.path\n",
    "import re\n",
    "import ipykernel\n",
    "import requests\n",
    "\n",
    "#try:  # Python 3\n",
    "#    from urllib.parse import urljoin\n",
    "#except ImportError:  # Python 2\n",
    "#    from urlparse import urljoin\n",
    "\n",
    "# Alternative that works for both Python 2 and 3:\n",
    "from requests.compat import urljoin\n",
    "\n",
    "try:  # Python 3 (see Edit2 below for why this may not work in Python 2)\n",
    "    from notebook.notebookapp import list_running_servers\n",
    "except ImportError:  # Python 2\n",
    "    import warnings\n",
    "    from IPython.utils.shimmodule import ShimWarning\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=ShimWarning)\n",
    "        from IPython.html.notebookapp import list_running_servers\n",
    "\n",
    "\n",
    "def get_notebook_path():\n",
    "    \"\"\"\n",
    "    Return the full path of the jupyter notebook.\n",
    "    !!! Doesn't work from VS code.\n",
    "    \"\"\"\n",
    "    kernel_id = re.search('kernel-(.*).json',\n",
    "                          ipykernel.connect.get_connection_file()).group(1)\n",
    "    servers = list_running_servers()\n",
    "    for ss in servers:\n",
    "        try:\n",
    "            response = requests.get(urljoin(ss['url'], 'api/sessions'),\n",
    "                                    params={'token': ss.get('token', '')}, timeout=1)\n",
    "            for nn in json.loads(response.text):\n",
    "                if nn['kernel']['id'] == kernel_id:\n",
    "                    relative_path = nn['notebook']['path']\n",
    "                    return os.path.join(ss['notebook_dir'], relative_path)\n",
    "        except Exception as e:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/run_local.ipynb\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(get_notebook_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import nbdev.export\n",
    "\n",
    "def find_default_export_for_notebook(notebook_path):\n",
    "    nb = nbdev.export.read_nb(notebook_path)\n",
    "    default = nbdev.export.find_default_export(nb['cells'])\n",
    "    return default\n",
    "\n",
    "def get_module_name():\n",
    "    return find_default_export_for_notebook(get_notebook_path())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_local\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(get_module_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcp_runner._nbdev'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "nbdev.export.get_nbdev_module().__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import nbdev.imports\n",
    "\n",
    "def get_package_name():\n",
    "    # see logic in https://github.com/fastai/nbdev/blob/master/nbdev/export.py\n",
    "    return str(nbdev.imports.Config().lib_path).split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcp_runner'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_package_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import io\n",
    "from threading import Thread\n",
    "from queue import Queue \n",
    "from nbdev.export import *\n",
    "\n",
    "\n",
    "def _reader(pipe, queue, pipe_name):\n",
    "    try:\n",
    "        with pipe:\n",
    "            for line in iter(pipe.readline, b''):\n",
    "                queue.put((pipe_name, line))\n",
    "    finally:\n",
    "        queue.put(None)\n",
    "        \n",
    "def _get_run_python_args(func, **kwargs):\n",
    "    package_name = get_package_name()\n",
    "    module_name = get_module_name()\n",
    "    function_name = func.__name__\n",
    "    args = ['python3', \n",
    "         '-u',\n",
    "         '-m', \n",
    "         'gcp_runner.entry_point',\n",
    "         '--module-name=%s' % package_name + '.' + module_name,\n",
    "         '--function-name=%s' % function_name]\n",
    "    return args\n",
    "        \n",
    "def run_python(func, **kwargs):\n",
    "    args = _get_run_python_args(func, **kwargs)\n",
    "    run_process(args, func_name)\n",
    "\n",
    "def run_process(args, **kwargs):\n",
    "    proc = subprocess.Popen(\n",
    "        args, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE, \n",
    "        bufsize=1)\n",
    "    \n",
    "    #(stdout, stderr) = proc.communicate(timeout=15)\n",
    "    \n",
    "    q = Queue()\n",
    "    Thread(target=_reader, args=[proc.stdout, q, 'stdout']).start()\n",
    "    Thread(target=_reader, args=[proc.stderr, q, 'stderr']).start()\n",
    "    #for _ in range(2):\n",
    "    for source, line in iter(q.get, None):\n",
    "        line = line.decode('utf-8').rstrip('\\r\\n')\n",
    "        if source == 'stderr':\n",
    "            print(\"\\x1b[31m{}\\x1b[0m\".format(line))\n",
    "        else:\n",
    "            print(line)\n",
    "    \n",
    "    return proc.poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_core.ipynb\n",
      "ai_platform_constants.ipynb\n",
      "ai_platform_runner.ipynb\n",
      "CONTRIBUTING.md\n",
      "Dockerfile\n",
      "docs\n",
      "entry_point.ipynb\n",
      "gcp_runner\n",
      "index.ipynb\n",
      "LICENSE\n",
      "local_runner.ipynb\n",
      "MANIFEST.in\n",
      "README.md\n",
      "sample_code.ipynb\n",
      "settings.ini\n",
      "setup.py\n"
     ]
    }
   ],
   "source": [
    "if run_process(['ls']):\n",
    "    print('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    print('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def run_docker(func, image_uri, docker_args=None, **kwargs):\n",
    "    package_name = get_package_name()\n",
    "    args = ['docker', 'run', '-v', \n",
    "            os.getcwd() + '/%s:/%s' % (package_name, package_name)]\n",
    "    if docker_args:\n",
    "        args.extend(docker_args)\n",
    "    args.append(image_uri)\n",
    "    run_python_args = _get_run_python_args(func, **kwargs)\n",
    "    args.extend(run_python_args)\n",
    "    print('running in docker:')\n",
    "    print(' '.join(args))\n",
    "    run_process(args) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "#IMPORTANT: we'll need to either copy entry_point.py to package,\n",
    "# or tell user to declare it and call into similar entry_point logic manually.\n",
    "#\n",
    "# !!! Doesn't work because of https://github.com/GoogleCloudPlatform/cloudml-samples/issues/476\n",
    "def run_on_ai_platform(func, job_dir):\n",
    "    package_name = get_package_name()\n",
    "    module_name = get_module_name()\n",
    "    function_name = func.__name__\n",
    "    args = ['gcloud', 'ai-platform', 'local', 'train',\n",
    "           \"--job-dir=%s\" % job_dir,\n",
    "           \"--module-name=%s.entry_point\" % package_name,\n",
    "           \"--package-path=%s/%s \" % (os.getcwd(), package_name),\n",
    "           \"--\",\n",
    "           \"--job-dir=%s\" % job_dir, \n",
    "           \"--module-name=%s.%s\" % (package_name, module_name),\n",
    "           \"--function-name=%s\" % function_name]\n",
    "    print('running training job using local Cloud AI:')\n",
    "    print(' '.join(args))\n",
    "    run_process(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitc34665d47f6a46efaf2c998849165367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
