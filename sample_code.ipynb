{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sample_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "\n",
    "def some_function_to_run_on_cloud():\n",
    "    print('running sample_code.some_function_to_run_on_cloud')\n",
    "    print('in main before sleep 1')\n",
    "    time.sleep(2)\n",
    "    print('in main after sleep 2')\n",
    "    time.sleep(5)\n",
    "    print('in main after sleep 3')\n",
    "    time.sleep(5)\n",
    "    print('in main after sleep 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in main before sleep 1\n",
      "in main after sleep 2\n",
      "in main after sleep 3\n",
      "in main after sleep 4\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "some_function_to_run_on_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running entrypoint function: gcp_runner.sample_code.some_function_to_run_on_cloud\n",
      "in main before sleep 1\n",
      "in main after sleep 2\n",
      "in main after sleep 3\n",
      "in main after sleep 4\n"
     ]
    }
   ],
   "source": [
    "!python3 -m gcp_runner.entry_point --module-name='gcp_runner.sample_code' --function-name='some_function_to_run_on_cloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running entrypoint function: gcp_runner.sample_code.some_function_to_run_on_cloud\n",
      "in main before sleep 1\n",
      "in main after sleep 2\n",
      "in main after sleep 3\n",
      "in main after sleep 4\n"
     ]
    }
   ],
   "source": [
    "!docker run -v `pwd`/gcp_runner:/gcp_runner 'gcr.io/deeplearning-platform-release/tf2-cpu.2-1' python3 -u -m gcp_runner.entry_point --module-name='gcp_runner.sample_code' --function-name='some_function_to_run_on_cloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subprocess.Popen object at 0x7f6057e2c750>\n",
      "running entrypoint function: gcp_runner.sample_code.some_function_to_run_on_cloud\n",
      "in main before sleep 1\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform local train --job-dir='job-dir' --module-name=gcp_runner.entry_point \\\n",
    "    --package-path=`pwd`/gcp_runner -- \\\n",
    "    --module-name='gcp_runner.sample_code' --function-name='some_function_to_run_on_cloud'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_core.ipynb\t\t     entry_point.ipynb\t README.md\n",
      "ai_platform_constants.ipynb  gcp_runner\t\t sample_code.ipynb\n",
      "ai_platform_runner.ipynb     index.ipynb\t settings.ini\n",
      "CONTRIBUTING.md\t\t     LICENSE\t\t setup.py\n",
      "Dockerfile\t\t     local_runner.ipynb\n",
      "docs\t\t\t     MANIFEST.in\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.748MB\n",
      "Step 1/13 : FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-1\n",
      " ---> 863c0351ef85\n",
      "Step 2/13 : WORKDIR /root\n",
      " ---> Using cache\n",
      " ---> aaae302f1f72\n",
      "Step 3/13 : RUN pip install google-cloud-bigquery\n",
      " ---> Using cache\n",
      " ---> 4c864de48c2a\n",
      "Step 4/13 : RUN pip install google-cloud-bigquery-storage\n",
      " ---> Using cache\n",
      " ---> 77c6a1d5616c\n",
      "Step 5/13 : RUN pip install google-cloud-logging\n",
      " ---> Using cache\n",
      " ---> 1e25c6790b5c\n",
      "Step 6/13 : ENV PROJECT_ID=alekseyv-scalableai-dev\n",
      " ---> Using cache\n",
      " ---> 1caffa032984\n",
      "Step 7/13 : ENV GOOGLE_APPLICATION_CREDENTIALS=/root/alekseyv-scalableai-dev-077efe757ef6.json\n",
      " ---> Using cache\n",
      " ---> d72a6d908f5e\n",
      "Step 8/13 : RUN pip install tensorboardX\n",
      " ---> Using cache\n",
      " ---> f51913756f18\n",
      "Step 9/13 : RUN pip install --no-deps tensorflow-io==0.7.2\n",
      " ---> Running in 73e94da3d3ef\n",
      "\u001b[91mERROR: Could not find a version that satisfies the requirement tensorflow-io==0.7.2 (from versions: 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.10.0, 0.11.0, 0.12.0)\n",
      "\u001b[0m\u001b[91mERROR: No matching distribution found for tensorflow-io==0.7.2\n",
      "\u001b[0mThe command '/bin/sh -c pip install --no-deps tensorflow-io==0.7.2' returned a non-zero code: 1\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1 ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code.ipynb.\n",
      "building Docker image:\n",
      "docker build -f Dockerfile -t gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1 ./\n",
      "Sending build context to Docker daemon  3.757MB\n",
      "Step 1/13 : FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-1\n",
      " ---> 863c0351ef85\n",
      "Step 2/13 : WORKDIR /root\n",
      " ---> Using cache\n",
      " ---> aaae302f1f72\n",
      "Step 3/13 : RUN pip install google-cloud-bigquery\n",
      " ---> Using cache\n",
      " ---> 4c864de48c2a\n",
      "Step 4/13 : RUN pip install google-cloud-bigquery-storage\n",
      " ---> Using cache\n",
      " ---> 77c6a1d5616c\n",
      "Step 5/13 : RUN pip install google-cloud-logging\n",
      " ---> Using cache\n",
      " ---> 1e25c6790b5c\n",
      "Step 6/13 : ENV PROJECT_ID=alekseyv-scalableai-dev\n",
      " ---> Using cache\n",
      " ---> 1caffa032984\n",
      "Step 7/13 : ENV GOOGLE_APPLICATION_CREDENTIALS=/root/alekseyv-scalableai-dev-077efe757ef6.json\n",
      " ---> Using cache\n",
      " ---> d72a6d908f5e\n",
      "Step 8/13 : RUN pip install tensorboardX\n",
      " ---> Using cache\n",
      " ---> f51913756f18\n",
      "Step 9/13 : RUN pip install --no-deps tensorflow-io\n",
      " ---> Using cache\n",
      " ---> c94963d1f268\n",
      "Step 10/13 : RUN pip install pandas\n",
      " ---> Using cache\n",
      " ---> 46584ba8a904\n",
      "Step 11/13 : RUN mkdir /root/model\n",
      " ---> Using cache\n",
      " ---> ea35f5d91deb\n",
      "Step 12/13 : RUN mkdir /root/gcp_runner\n",
      " ---> Running in 7ef76225b8c0\n",
      "Removing intermediate container 7ef76225b8c0\n",
      " ---> 4789d7548556\n",
      "Step 13/13 : COPY gcp_runner/* /root/gcp_runner\n",
      "\u001b[31mWhen using COPY with more than one source file, the destination must be a directory and end with a /\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "import time\n",
    "\n",
    "from gcp_runner import core\n",
    "\n",
    "core.export_and_reload_all()\n",
    "\n",
    "#gcp_runner.run_local.run_python(some_function_to_run_on_cloud)\n",
    "\n",
    "# gcp_runner.run_local.run_docker(\n",
    "#     some_function_to_run_on_cloud, \n",
    "#     'gcr.io/deeplearning-platform-release/tf2-cpu.2-1')\n",
    "\n",
    "# gcp_runner.local_runner.run_on_ai_platform(\n",
    "#     some_function_to_run_on_cloud, \n",
    "#     'job-dir')\n",
    "\n",
    "# need to put package to docker container\n",
    "gcp_runner.ai_platform_runner.run_docker_image(\n",
    "    some_function_to_run_on_cloud,\n",
    "    'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir',\n",
    "    build_docker_file='Dockerfile',\n",
    "    master_image_uri='gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1')\n",
    "\n",
    "# gcp_runner.ai_platform_runner.run_package(\n",
    "#     some_function_to_run_on_cloud,\n",
    "#     'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_platform_runner.py  __init__.py\t_nbdev.py     sample_code.py\n",
      "core.py\t\t       __init__.pyc\t__pycache__   sample_code.pyc\n",
      "entry_point.py\t       local_runner.py\trun_local.py\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subprocess.Popen object at 0x7fade12ae810>\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform local train --job-dir=job-dir --module-name=gcp_runner.sample_code --package-path=/usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner -- --job-dir=job-dir --module-name=gcp_runner.entry_point --function-name=some_function_to_run_on_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subprocess.Popen object at 0x7f0a7749e690>\n",
      "running entrypoint function: gcp_runner.sample_code.some_function_to_run_on_cloud\n",
      "in main before sleep 1\n"
     ]
    }
   ],
   "source": [
    "!bash gcloud ai-platform local train --job-dir='job-dir' --module-name='gcp_runner.entry_point' --package-path='/usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner' -- --job-dir='job-dir' --module-name=gcp_runner.sample_code --function-name=some_function_to_run_on_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subprocess.Popen object at 0x7efea74df610>\n",
      "running entrypoint function: gcp_runner.sample_code.some_function_to_run_on_cloud\n",
      "in main before sleep 1\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform local train --job-dir=job-dir --module-name=gcp_runner.entry_point --package-path=/usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner  -- --job-dir=job-dir --module-name=gcp_runner.sample_code --function-name=some_function_to_run_on_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted run_local.ipynb.\n",
      "Converted sample_code.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitc34665d47f6a46efaf2c998849165367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
