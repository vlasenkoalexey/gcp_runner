{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ai_platform_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from enum import Enum\n",
    "\n",
    "class AcceleratorType(Enum):\n",
    "    NVIDIA_TESLA_K80 = 'nvidia-tesla-k80'\n",
    "    NVIDIA_TESLA_P100 = 'nvidia-tesla-p100'\n",
    "    NVIDIA_TESLA_V100 = 'nvidia-tesla-v100'\n",
    "    NVIDIA_TESLA_P4 = 'nvidia-tesla-p4'\n",
    "    NVIDIA_TESLA_T4 = 'nvidia-tesla-t4'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training#--master-machine-type\n",
    "class ScaleTier(Enum):\n",
    "    \"\"\"Single worker instance. \n",
    "    This tier is suitable for learning how to use AI Platform, and for experimenting \n",
    "    with new models using small datasets.\"\"\"\n",
    "    BASIC = 'basic'\n",
    "    \"\"\"Single worker instance with a GPU.\"\"\"\n",
    "    BASIC_GPU = 'basic-gpu'\n",
    "    \"\"\"Single worker instance with a Cloud TPU.\"\"\"\n",
    "    BASIC_TPU = 'basic-tpu'\n",
    "    \"\"\"The CUSTOM tier is not a set tier, but rather enables you to use your\n",
    "    own cluster specification. When you use this tier, set values to\n",
    "    configure your processing cluster according to these guidelines\"\"\"\n",
    "    CUSTOM = 'custom'\n",
    "    \"\"\"Many workers and a few parameter servers.\"\"\"\n",
    "    STANDARD_1 = 'standard-1';\n",
    "    \"\"\"A large number of workers with many parameter servers.\"\"\"\n",
    "    PREMIUM_1 = 'premium-1'    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# https://cloud.google.com/compute/docs/machine-types\n",
    "class MachineType(Enum):\n",
    "    N1_STANDARD_4 =     'n1-standard-4'\n",
    "    N1_STANDARD_8 =     'n1-standard-8'\n",
    "    N1_STANDARD_16 =    'n1-standard-16'\n",
    "    N1_STANDARD_32 =    'n1-standard-32'\n",
    "    N1_STANDARD_64 =    'n1-standard-64'\n",
    "    N1_STANDARD_96 =    'n1-standard-96'\n",
    "    N1_HIGHMEM_2 =      'n1-highmem-2'\n",
    "    N1_HIGHMEM_4 =      'n1-highmem-4'\n",
    "    N1_HIGHMEM_8 =      'n1-highmem-8'\n",
    "    N1_HIGHMEM_16 =     'n1-highmem-16'\n",
    "    N1_HIGHMEM_32 =     'n1-highmem-32'\n",
    "    N1_HIGHMEM_64 =     'n1-highmem-64'\n",
    "    N1_HIGHMEM_96 =     'n1-highmem-96'\n",
    "    N1_HIGHCPU_16 =     'n1-highcpu-16'\n",
    "    N1_HIGHCPU_32 =     'n1-highcpu-32'\n",
    "    N1_HIGHCPU_64 =     'n1-highcpu-64'\n",
    "    N1_HIGHCPU_96 =     'n1-highcpu-96'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DistributionStrategyType(Enum):\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "    \n",
    "    MIRRORED_STRATEGY =              \"tf.distribute.MirroredStrategy\"\n",
    "    ONE_DEVICE_STRATEGY =            \"tf.distribute.OneDeviceStrategy\"\n",
    "    CENTRAL_STORAGE_STRATEGY =       \"tf.distribute.experimental.CentralStorageStrategy\"\n",
    "    PARAMETER_SERVERSTRATEGY =       \"tf.distribute.experimental.ParameterServerStrategy\"\n",
    "    MULTI_WORKER_MIRRORED_STRATEGY = \"tf.distribute.experimental.MultiWorkerMirroredStrategy\"\n",
    "    TPU_STRATEGY =                   \"tf.distribute.experimental.TPUStrategy\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitc34665d47f6a46efaf2c998849165367"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
