{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ai_platform_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    echo \"Submitting an AI Platform job...\"\n",
    "    # see https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training\n",
    "    gcloud beta ai-platform jobs submit training ${JOB_NAME} \\\n",
    "            ${CONFIG_FIX} \\\n",
    "            --scale-tier=${SCALE_TIER} \\\n",
    "            --region=${REGION} \\\n",
    "            --master-image-uri=${IMAGE_URI} \\\n",
    "            --stream-logs \\\n",
    "            ${CONFIG} \\\n",
    "            -- python trainer/trainer.py --job-dir=${MODEL_DIR} --train-location=cloud $@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcp_runner import core\n",
    "core.export_and_reload_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import inspect \n",
    "from gcp_runner import ai_platform_constants\n",
    "\n",
    "def _get_not_none(arg, default):\n",
    "    return default if arg is None else arg\n",
    "\n",
    "def _get_common_args(\n",
    "    job_dir,\n",
    "    job_name=None,\n",
    "    region=None,\n",
    "    scale_tier: ai_platform_constants.ScaleTier = ai_platform_constants.ScaleTier.BASIC,\n",
    "    master_machine_type: ai_platform_constants.MachineType = None,\n",
    "    master_image_uri=None,\n",
    "    master_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    master_accelerator_count=None,\n",
    "    parameter_machine_type: ai_platform_constants.MachineType = None,\n",
    "    parameter_machine_count=None,\n",
    "    parameter_image_uri=None,\n",
    "    parameter_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    parameter_accelerator_count=None,\n",
    "    worker_machine_type: ai_platform_constants.MachineType = None,\n",
    "    worker_machine_count=None,\n",
    "    worker_image_uri=None,\n",
    "    work_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    work_accelerator_count=None,\n",
    "    use_chief_in_tf_config=True,\n",
    "    distribution_strategy_type: ai_platform_constants.DistributionStrategyType = None):   \n",
    "    args = []\n",
    "    \n",
    "    if distribution_strategy_type and scale_tier == ai_platform_constants.ScaleTier.CUSTOM:\n",
    "        master_machine_type = _get_not_none(master_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "        if distribution_strategy_type == ai_platform_constants.DistributionStrategyType.MIRRORED_STRATEGY:\n",
    "            master_accelerator_type = _get_not_none (master_accelerator_type, ai_platform_constants.AcceleratorType.NVIDIA_TESLA_K80)\n",
    "            master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "            worker_machine_count = _get_not_none(worker_machine_count, 0)\n",
    "        elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.CENTRAL_STORAGE_STRATEGY:\n",
    "            master_accelerator_type = _get_not_none (master_accelerator_type, ai_platform_constants.AcceleratorType.NVIDIA_TESLA_K80)\n",
    "            master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "            worker_machine_count = _get_not_none(worker_machine_count, 0)\n",
    "        elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.PARAMETER_SERVERSTRATEGY:\n",
    "            parameter_machine_type = _get_not_none(parameter_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "            parameter_machine_count = _get_not_none(parameter_machine_count, 1)\n",
    "            worker_machine_count = _get_not_none(worker_machine_count, 2)\n",
    "        elif args.distribution_strategy == ai_platform_constants.DistributionStrategyType.MULTI_WORKER_MIRRORED_STRATEGY:\n",
    "            master_accelerator_type = _get_not_none (master_accelerator_type, ai_platform_constants.AcceleratorType.NVIDIA_TESLA_K80)\n",
    "            master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "            worker_machine_count = _get_not_none(worker_machine_count, 2)\n",
    "            work_accelerator_type = _get_not_none (work_accelerator_type, ai_platform_constants.AcceleratorType.NVIDIA_TESLA_K80)\n",
    "            worker_machine_type = _get_not_none(worker_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    \n",
    "    for key, value in locals().items():\n",
    "        # print(key + '=' + str(value))\n",
    "        if key != 'args' and key != 'distribution_strategy_type' and value:\n",
    "            if key.endswith('_type') or key == 'scale_tier':\n",
    "                args.append(\"--%s=%s\" % (key.replace('_', '-'), value.value))\n",
    "            else:\n",
    "                args.append(\"--%s=%s\" % (key.replace('_', '-'), value))\n",
    "    \n",
    "    return args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "from gcp_runner.core import build_and_push_docker_image, run_process, get_run_python_args\n",
    "from gcp_runner import ai_platform_constants\n",
    "\n",
    "def run_docker_image(\n",
    "    func, \n",
    "    job_dir,\n",
    "    build_docker_file=None,\n",
    "    dry_run=False,\n",
    "    job_name=None,\n",
    "    region=None,\n",
    "    scale_tier: ai_platform_constants.ScaleTier =  ai_platform_constants.ScaleTier.BASIC,\n",
    "    master_machine_type: ai_platform_constants.MachineType = None,\n",
    "    master_image_uri=None,\n",
    "    master_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    master_accelerator_count=None,\n",
    "    parameter_machine_type: ai_platform_constants.MachineType = None,\n",
    "    parameter_machine_count=None,\n",
    "    parameter_image_uri=None,\n",
    "    parameter_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    parameter_accelerator_count=None,\n",
    "    worker_machine_type: ai_platform_constants.MachineType = None,\n",
    "    worker_machine_count=None,\n",
    "    worker_image_uri=None,\n",
    "    work_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    work_accelerator_count=None,\n",
    "    use_chief_in_tf_config=True,\n",
    "    distribution_strategy_type: ai_platform_constants.DistributionStrategyType = None,\n",
    "    **kwargs):\n",
    "    \n",
    "    if not master_image_uri:\n",
    "        raise ValueError('master_image_uri argument is required')\n",
    "        \n",
    "    if not job_name:\n",
    "        job_name = 'ai_platform_runner_train_docker_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "    if build_docker_file is not None:\n",
    "        result = build_and_push_docker_image(build_docker_file, master_image_uri, dry_run=dry_run)\n",
    "        if result:\n",
    "            return result\n",
    "    \n",
    "    # see https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training\n",
    "    args = ['gcloud', 'ai-platform', 'jobs', 'submit', 'training', job_name,\n",
    "           \"--stream-logs\"]\n",
    "    \n",
    "    common_args = _get_common_args(\n",
    "        job_dir,\n",
    "        region = region,\n",
    "        scale_tier = scale_tier,\n",
    "        master_machine_type = master_machine_type,\n",
    "        master_image_uri = master_image_uri,\n",
    "        master_accelerator_type = master_accelerator_type,\n",
    "        master_accelerator_count = master_accelerator_count,\n",
    "        parameter_machine_type = parameter_machine_type,\n",
    "        parameter_machine_count = parameter_machine_count,\n",
    "        parameter_image_uri = parameter_image_uri,\n",
    "        parameter_accelerator_type = parameter_accelerator_type,\n",
    "        parameter_accelerator_count = parameter_accelerator_count,\n",
    "        worker_machine_type = worker_machine_type,\n",
    "        worker_machine_count = worker_machine_count,\n",
    "        worker_image_uri = worker_image_uri,\n",
    "        work_accelerator_type = work_accelerator_type,\n",
    "        work_accelerator_count = work_accelerator_count,\n",
    "        use_chief_in_tf_config = use_chief_in_tf_config,\n",
    "        distribution_strategy_type = distribution_strategy_type)\n",
    "    args.extend(common_args)\n",
    "    print(common_args)\n",
    "    print(master_image_uri)\n",
    "    \n",
    "    args.append('--')\n",
    "    \n",
    "    run_python_args = get_run_python_args(func, **kwargs)\n",
    "    args.extend(run_python_args)\n",
    "    args.append(\"--job-dir=%s\" % job_dir)\n",
    "    if distribution_strategy_type:\n",
    "        args.append(\"--distribution-strategy-type=%s\" % distribution_strategy_type)\n",
    "    \n",
    "    print('running training job using Docker image Google Cloud Platform AI:')\n",
    "    print(' '.join(args).replace(' --', '\\n --').replace('\\n', ' \\\\ \\n'))\n",
    "    if not dry_run:\n",
    "        return gcp_runner.local_runner.run_process(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200325_163837'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "echo \"Submitting an AI Platform job...\"\n",
    "# see https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training\n",
    "gcloud ai-platform jobs submit training ${JOB_NAME} \\\n",
    "        --config=${PWD}/scripts/config_fix.yaml \\\n",
    "        --scale-tier=${SCALE_TIER} \\\n",
    "        --job-dir=${MODEL_DIR} \\\n",
    "        --runtime-version=${RUNTIME_VERSION} \\\n",
    "        --region=${REGION} \\\n",
    "        --module-name=trainer.trainer \\\n",
    "        --package-path=${PACKAGE_PATH}  \\\n",
    "        --master-machine-type=n1-highcpu-16 \\\n",
    "        --stream-logs \\\n",
    "        ${CONFIG} \\\n",
    "        -- \\\n",
    "        --job-dir=${MODEL_DIR} --train-location=cloud $@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import datetime\n",
    "from gcp_runner.core import get_run_python_args, run_process, get_package_name, get_module_name\n",
    "from gcp_runner import ai_platform_constants\n",
    "\n",
    "#IMPORTANT: we'll need to either copy entry_point.py to package,\n",
    "# or tell user to declare it and call into similar entry_point logic manually.\n",
    "\n",
    "def run_package(\n",
    "    func,\n",
    "    job_dir,\n",
    "    job_name=None,\n",
    "    runtime_version='2.1', \n",
    "    python_version='3.7', \n",
    "    dry_run=False,\n",
    "    region=None,\n",
    "    scale_tier: ai_platform_constants.ScaleTier =  ai_platform_constants.ScaleTier.BASIC,\n",
    "    master_machine_type: ai_platform_constants.MachineType = None,\n",
    "    master_image_uri=None,\n",
    "    master_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    master_accelerator_count=None,\n",
    "    parameter_machine_type: ai_platform_constants.MachineType = None,\n",
    "    parameter_machine_count=None,\n",
    "    parameter_image_uri=None,\n",
    "    parameter_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    parameter_accelerator_count=None,\n",
    "    worker_machine_type: ai_platform_constants.MachineType = None,\n",
    "    worker_machine_count=None,\n",
    "    worker_image_uri=None,\n",
    "    work_accelerator_type: ai_platform_constants.AcceleratorType = None,\n",
    "    work_accelerator_count=None,\n",
    "    use_chief_in_tf_config=True,\n",
    "    distribution_strategy_type: ai_platform_constants.DistributionStrategyType = None,    \n",
    "    **kwargs):\n",
    "    \n",
    "    if not job_name:\n",
    "        job_name = 'ai_platform_runner_train_package_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # see https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training\n",
    "    package_name = get_package_name()\n",
    "    module_name = get_module_name()\n",
    "    function_name = func.__name__\n",
    "    args = [\n",
    "        'gcloud', 'ai-platform', 'jobs', 'submit', 'training', job_name,\n",
    "        \"--runtime-version=%s\" % runtime_version,\n",
    "        \"--python-version=%s\" % python_version,\n",
    "        \"--stream-logs\",\n",
    "        \"--module-name=%s.entry_point\" % package_name,\n",
    "        \"--package-path=%s/%s\" % (os.getcwd(), package_name)]\n",
    "\n",
    "    common_args = _get_common_args(\n",
    "        job_dir,\n",
    "        region = region,\n",
    "        scale_tier = scale_tier,\n",
    "        master_machine_type = master_machine_type,\n",
    "        master_image_uri = master_image_uri,\n",
    "        master_accelerator_type = master_accelerator_type,\n",
    "        master_accelerator_count = master_accelerator_count,\n",
    "        parameter_machine_type = parameter_machine_type,\n",
    "        parameter_machine_count = parameter_machine_count,\n",
    "        parameter_image_uri = parameter_image_uri,\n",
    "        parameter_accelerator_type = parameter_accelerator_type,\n",
    "        parameter_accelerator_count = parameter_accelerator_count,\n",
    "        worker_machine_type = worker_machine_type,\n",
    "        worker_machine_count = worker_machine_count,\n",
    "        worker_image_uri = worker_image_uri,\n",
    "        work_accelerator_type = work_accelerator_type,\n",
    "        work_accelerator_count = work_accelerator_count,\n",
    "        use_chief_in_tf_config = use_chief_in_tf_config,\n",
    "        distribution_strategy_type = distribution_strategy_type)\n",
    "    args.extend(common_args)    \n",
    "    \n",
    "    package_args = [\n",
    "        \"--\",\n",
    "        \"--job-dir=%s\" % job_dir, \n",
    "        \"--module-name=%s.%s\" % (package_name, module_name),\n",
    "        \"--function-name=%s\" % function_name]\n",
    "    args.extend(package_args)\n",
    "    \n",
    "    if distribution_strategy_type:\n",
    "        args.append(\"--distribution-strategy-type=%s\" % distribution_strategy_type)\n",
    "    \n",
    "    print('running training job using package on Google Cloud Platform AI:')\n",
    "    print(' '.join(args).replace(' --', '\\n --').replace('\\n', ' \\\\ \\n'))\n",
    "    \n",
    "    if not dry_run:\n",
    "        return gcp_runner.local_runner.run_process(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitc34665d47f6a46efaf2c998849165367"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
