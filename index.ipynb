{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform notebook runner for [nbdev](https://github.com/fastai/nbdev/tree/master/nbdev)\n",
    "\n",
    "> Allows running any Jupyter notebook function on Google Cloud Platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: upload to pypi\n",
    "`pip install gcp_runner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some function that we want to run in notebook as well as on Google Cloud.\n",
    "Note that cell has to be marked with export attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "\n",
    "def some_function_to_run_on_cloud():\n",
    "    print('running some_function_to_run_on_cloud')\n",
    "    print('in main before sleep 1')\n",
    "    time.sleep(2)\n",
    "    print('in main after sleep 2')\n",
    "    time.sleep(5)\n",
    "    print('in main after sleep 3')\n",
    "    time.sleep(5)\n",
    "    print('in main after sleep 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running it in notebook as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running some_function_to_run_on_cloud\n",
      "in main before sleep 1\n",
      "in main after sleep 2\n",
      "in main after sleep 3\n",
      "in main after sleep 4\n"
     ]
    }
   ],
   "source": [
    "some_function_to_run_on_cloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating project\n",
    "If you do any changes, call `gcp_runner.core.export_and_reload_all` to convert all notebooks to python, and reload all modules. Note that modules are reloaded in an order defined by notebook names to make sure that dependencies are processed correctly. If there are errors in one of the modules, you can ignore them by setting ignore_errors=True. Or just restart Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcp_runner.core import export_and_reload_all\n",
    "export_and_reload_all(silent=True, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing code locally\n",
    "Test that code can be executed locally as a Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in gcp_runner entry point\n",
      "running entrypoint function: gcp_runner.index.some_function_to_run_on_cloud\n",
      "running some_function_to_run_on_cloud\n",
      "in main before sleep 1\n",
      "in main after sleep 2\n",
      "in main after sleep 3\n",
      "in main after sleep 4\n"
     ]
    }
   ],
   "source": [
    "import gcp_runner.local_runner\n",
    "gcp_runner.local_runner.run_python(some_function_to_run_on_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can test that code can be executed locally as a docker container.\n",
    "In order to build your own Docker file, set `build_docker_file` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcp_runner.local_runner\n",
    "gcp_runner.local_runner.run_docker(\n",
    "    some_function_to_run_on_cloud,\n",
    "    'gcr.io/deeplearning-platform-release/tf2-cpu.2-1',\n",
    "    build_docker_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Running in Docker container:  \n",
    "docker run -v /usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner:/gcp_runner gcr.io/deeplearning-platform-release/tf2-cpu.2-1 python -u -m gcp_runner.entry_point --module-name=gcp_runner.index --function-name=some_function_to_run_on_cloud\n",
    "in gcp_runner entry point  \n",
    "running entrypoint function: gcp_runner.index.some_function_to_run_on_cloud  \n",
    "running some_function_to_run_on_cloud  \n",
    "in main before sleep 1  \n",
    "in main after sleep 2  \n",
    "in main after sleep 3  \n",
    "in main after sleep 4  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on Google Cloud AI Platform\n",
    "\n",
    "TODO: describe google cloud sdk setup\n",
    "\n",
    "Running as a package on Google Cloud AI Platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcp_runner.ai_platform_runner\n",
    "\n",
    "gcp_runner.ai_platform_runner.run_package(\n",
    "     some_function_to_run_on_cloud, \n",
    "     'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Trimmed output:  \n",
    "Running training job using package on Google Cloud Platform AI:  \n",
    "gcloud ai-platform jobs submit training ai_platform_runner_train_package_20200327_131147 \\\\  \n",
    " --runtime-version=2.1 \\\\   \n",
    " --python-version=3.7 \\\\   \n",
    " --stream-logs \\\\   \n",
    " --module-name=gcp_runner.entry_point \\\\   \n",
    " --package-path=/usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner \\\\  \n",
    " --job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir \\\\  \n",
    " --scale-tier=basic \\\\  \n",
    " --use-chief-in-tf-config=True \\\\  \n",
    " -- \\\\  \n",
    " --job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir \\\\  \n",
    " --module-name=gcp_runner.index \\\\  \n",
    " --function-name=some_function_to_run_on_cloud  \n",
    "        \n",
    "Job [ai_platform_runner_train_package_20200327_131147] submitted successfully.  \n",
    "INFO\t2020-03-27 13:11:51 -0700\tservice\t\tValidating job requirements...  \n",
    "INFO\t2020-03-27 13:11:51 -0700\tservice\t\tJob creation request has been successfully validated.  \n",
    "INFO\t2020-03-27 13:11:51 -0700\tservice\t\tJob ai_platform_runner_train_package_20200327_131147 is queued.  \n",
    "INFO\t2020-03-27 13:11:51 -0700\tservice\t\tWaiting for job to be provisioned.  \n",
    "INFO\t2020-03-27 13:11:53 -0700\tservice\t\tWaiting for training program to start.  \n",
    "...  \n",
    "INFO\t2020-03-27 13:13:23 -0700\tmaster-replica-0\t\tRunning command: python3 -m gcp_runner.entry_point --job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir --module-name=gcp_runner.index --function-name=some_function_to_run_on_cloud --job-dir gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tin gcp_runner entry point  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\trunning entrypoint function: gcp_runner.index.some_function_to_run_on_cloud  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tadditional args: ['--job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir', '--job-dir', 'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir']  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\trunning some_function_to_run_on_cloud  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tin main before sleep 1  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tin main after sleep 2  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tin main after sleep 3  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tin main after sleep 4  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tModule completed; cleaning up.  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tClean up finished.  \n",
    "INFO\t2020-03-27 13:13:35 -0700\tmaster-replica-0\t\tTask completed successfully.  \n",
    "state: SUCCEEDED \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running as a custom Docker container on Google Cloud AI Platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcp_runner.ai_platform_runner\n",
    "\n",
    "gcp_runner.ai_platform_runner.run_docker_image(\n",
    "    some_function_to_run_on_cloud,\n",
    "    'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir',\n",
    "    build_docker_file='Dockerfile',\n",
    "    master_image_uri='gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Trimmed output:  \n",
    "INFO\t2020-03-27 13:01:57 -0700\tmaster-replica-0\t\trunning some_function_to_run_on_cloud  \n",
    "INFO\t2020-03-27 13:01:57 -0700\tmaster-replica-0\t\tin main before sleep 1  \n",
    "INFO\t2020-03-27 13:01:59 -0700\tmaster-replica-0\t\tin main after sleep 2  \n",
    "INFO\t2020-03-27 13:02:04 -0700\tmaster-replica-0\t\tin main after sleep 3  \n",
    "INFO\t2020-03-27 13:02:09 -0700\tmaster-replica-0\t\tin main after sleep 4  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: example how to run distributed training\n",
    "TODO: example how to run distributed hyper parameter tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Google Cloud Kubernetes\n",
    "\n",
    "- TODO: describe how to setup and configure Kubernetes\n",
    "- TODO: describe that it is faster to use Kubernetes for iterative work\n",
    "- TODO: distributed training\n",
    "- TODO: distributed HP tuning\n",
    "\n",
    "Note that Kubernetes doesn't offer convenient way of streaming logs, so currently script is going to keep pulling logs until you terminate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcp_runner.kubernetes_runner\n",
    "\n",
    "gcp_runner.kubernetes_runner.run_docker_image(\n",
    "    some_function_to_run_on_cloud,\n",
    "    'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir',\n",
    "    build_docker_file='Dockerfile',\n",
    "    image_uri='gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Trimmed output:  \n",
    "kubernetes-runner-train-docker-chief-0\t\trunning some_function_to_run_on_cloud  \n",
    "kubernetes-runner-train-docker-chief-0\t\tin main before sleep 1  \n",
    "kubernetes-runner-train-docker-chief-0\t\tin main after sleep 2  \n",
    "kubernetes-runner-train-docker-chief-0\t\tin main after sleep 3  \n",
    "kubernetes-runner-train-docker-chief-0\t\tin main after sleep 4  \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
