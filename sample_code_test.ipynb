{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sample_code_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "\n",
    "def some_function_to_run_on_cloud():\n",
    "    print('running sample_code_test.some_function_to_run_on_cloud')\n",
    "    print('in main before sleep 1')\n",
    "    time.sleep(2)\n",
    "    print('in main after sleep 2')\n",
    "    time.sleep(5)\n",
    "    print('in main after sleep 3')\n",
    "    time.sleep(5)\n",
    "    print('in main after sleep 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "some_function_to_run_on_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m gcp_runner.entry_point --module-name='gcp_runner.sample_code' --function-name='some_function_to_run_on_cloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v `pwd`/gcp_runner:/gcp_runner 'gcr.io/deeplearning-platform-release/tf2-cpu.2-1' python3 -u -m gcp_runner.entry_point --module-name='gcp_runner.sample_code' --function-name='some_function_to_run_on_cloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform local train --job-dir='job-dir' --module-name=gcp_runner.entry_point \\\n",
    "    --package-path=`pwd`/gcp_runner -- \\\n",
    "    --module-name='gcp_runner.sample_code' --function-name='some_function_to_run_on_cloud'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -f Dockerfile -t gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1 ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from gcp_runner.core import export_and_reload_all\n",
    "export_and_reload_all()\n",
    "\n",
    "gcp_runner.run_local.run_python(some_function_to_run_on_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kubernetes_runner.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code_test.ipynb.\n",
      "Running training job using local Cloud AI:\n",
      "gcloud ai-platform local train \\ \n",
      " --job-dir=job-dir \\ \n",
      " --module-name=gcp_runner.entry_point \\ \n",
      " --package-path=/usr/local/google/home/alekseyv/vlasenkoalexey/gcp_runner/gcp_runner  \\ \n",
      " -- \\ \n",
      " --job-dir=job-dir \\ \n",
      " --module-name=gcp_runner.sample_code_test \\ \n",
      " --function-name=some_function_to_run_on_cloud\n",
      "\u001b[31m<subprocess.Popen object at 0x7f6db97cb6d0>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import time\n",
    "\n",
    "import gcp_runner\n",
    "from gcp_runner.core import export_and_reload_all\n",
    "#export_and_reload_all(silent=True, ignore_errors=False)\n",
    "export_and_reload_all()\n",
    "\n",
    "#gcp_runner.run_local.run_python(some_function_to_run_on_cloud)\n",
    "\n",
    "# gcp_runner.run_local.run_docker(\n",
    "#     some_function_to_run_on_cloud, \n",
    "#     'gcr.io/deeplearning-platform-release/tf2-cpu.2-1')\n",
    "\n",
    "gcp_runner.local_runner.run_on_ai_platform(\n",
    "    some_function_to_run_on_cloud, \n",
    "    'job-dir')\n",
    "\n",
    "# need to put package to docker container\n",
    "# gcp_runner.ai_platform_runner.run_docker_image(\n",
    "#     some_function_to_run_on_cloud,\n",
    "#     'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir',\n",
    "#     build_docker_file='Dockerfile',\n",
    "#     master_image_uri='gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1')\n",
    "\n",
    "# gcp_runner.ai_platform_runner.run_package(\n",
    "#     some_function_to_run_on_cloud,\n",
    "#     'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir')\n",
    "\n",
    "#build_docker_file='Dockerfile',\n",
    "\n",
    "\n",
    "# gcp_runner.kubernetes_runner.run_docker_image(\n",
    "#     some_function_to_run_on_cloud,\n",
    "#     'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir',\n",
    "#     image_uri='gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_ai_platform_constants.ipynb.\n",
      "Converted ai_platform_runner.ipynb.\n",
      "Converted entry_point.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kubernetes_runner.ipynb.\n",
      "Converted local_runner.ipynb.\n",
      "Converted sample_code_test.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcp_runner.core import export_and_reload_all\n",
    "export_and_reload_all(silent=True, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcp_runner.ai_platform_runner\n",
    "\n",
    "gcp_runner.ai_platform_runner.run_package(\n",
    "     some_function_to_run_on_cloud, \n",
    "     'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see job output in tensorboard, run following command:\n",
      "tensorboard --logdir=%s gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir\n",
      "Generating kubernetes YAML file:\n",
      "kind: Service\n",
      "apiVersion: v1\n",
      "metadata:\n",
      "  name: kubernetes-runner-train-docker-chief-0\n",
      "spec:\n",
      "  type: ClusterIP\n",
      "  clusterIP: None\n",
      "  selector:\n",
      "    job: kubernetes-runner-train-docker-chief-0\n",
      "  ports:\n",
      "  - port: 5000\n",
      "---\n",
      "kind: Pod\n",
      "apiVersion: v1\n",
      "metadata:\n",
      "  name: kubernetes-runner-train-docker-chief-0\n",
      "  labels:\n",
      "    job: kubernetes-runner-train-docker-chief-0\n",
      "  annotations:\n",
      "    tf-version.cloud-tpus.google.com: \"2.1\"\n",
      "spec:\n",
      "  hostNetwork: true\n",
      "  dnsPolicy: ClusterFirstWithHostNet\n",
      "  restartPolicy: Never\n",
      "  containers:\n",
      "  - name: gcp-runner-image\n",
      "    image: gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1\n",
      "    imagePullPolicy: Always\n",
      "    resources:\n",
      "      limits:\n",
      "        cpu: 3\n",
      "        memory: 12G\n",
      "        nvidia.com/gpu: 2\n",
      "\n",
      "    env:\n",
      "    - name: TF_CONFIG\n",
      "      value: \"{\n",
      "  \\\"cluster\\\": {\\\"chief\\\": [\\\"kubernetes-runner-train-docker-chief-0:5000\\\"]},\n",
      "  \\\"task\\\": {\n",
      "    \\\"type\\\":  \\\"chief\\\",\n",
      "    \\\"index\\\": 0\n",
      "  },\n",
      "  \\\"environment\\\": \\\"cloud\\\"\n",
      "}\"\n",
      "    ports:\n",
      "    - containerPort: 5000\n",
      "    command:\n",
      "    - \"python\"\n",
      "    - \"-u\"\n",
      "    - \"-m\"\n",
      "    - \"gcp_runner.entry_point\"\n",
      "    - \"--module-name=gcp_runner.sample_code_test\"\n",
      "    - \"--function-name=some_function_to_run_on_cloud\"\n",
      "    - \"--job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir\"\n",
      "    - \"--distribution-strategy-type=tf.distribute.MirroredStrategy\"\n",
      "    - \"--use-distribution-strategy-scope\"\n",
      "---\n",
      "\n",
      "Deleting all resources on Kubernetes cluster:\n",
      "kubectl delete namespace kubernetes-runner-namespace\n",
      "namespace \"kubernetes-runner-namespace\" deleted\n",
      "Creating Kubernetes kubernetes-runner-namespace namespace:\n",
      "kubectl create namespace kubernetes-runner-namespace\n",
      "namespace/kubernetes-runner-namespace created\n",
      "Creating Kubernetes cluster:\n",
      "kubectl create -f /var/folders/0c/_9t2rb612zq01d325yh__5ph0069sb/T/tmprq5bw0ib --namespace=kubernetes-runner-namespace\n",
      "service/kubernetes-runner-train-docker-chief-0 created\n",
      "pod/kubernetes-runner-train-docker-chief-0 created\n",
      "See logs at:\n",
      "https://pantheon.corp.google.com/logs/viewer?minLogLevel=0&expandAll=false&advancedFilter=resource.type%3D%22container%22%0Aresource.labels.namespace_id%3D%22kubernetes-runner-namespace%22&dateRangeStart=2020-04-01T23:32:11Z\n",
      "Polling Kubernetes logs:\n",
      "logs since 2020-04-01T23:32:11+00:00\n",
      "kubernetes-runner-train-docker-chief-0\t\tin gcp_runner entry point\n",
      "kubernetes-runner-train-docker-chief-0\t\trunning entrypoint function: gcp_runner.sample_code_test.some_function_to_run_on_cloud\n",
      "kubernetes-runner-train-docker-chief-0\t\tadditional args: ['--job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir', '--distribution-strategy-type=tf.distribute.MirroredStrategy', '--use-distribution-strategy-scope']\n",
      "kubernetes-runner-train-docker-chief-0\t\t/root/gcp_runner/entry_point.py:30: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "kubernetes-runner-train-docker-chief-0\t\t  args_spec = inspect.getargspec(func)\n",
      "kubernetes-runner-train-docker-chief-0\t\trunning sample_code_test.some_function_to_run_on_cloud\n",
      "kubernetes-runner-train-docker-chief-0\t\tin main before sleep 1\n",
      "kubernetes-runner-train-docker-chief-0\t\tin main after sleep 2\n",
      "kubernetes-runner-train-docker-chief-0\t\tin main after sleep 3\n",
      "kubernetes-runner-train-docker-chief-0\t\tin main after sleep 4\n",
      "logs since 2020-04-01T23:33:12+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:33:12+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:33:12+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:33:12+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:33:12+00:00\n",
      "kubernetes-runner-train-docker-chief-0\t\tin gcp_runner entry point\n",
      "kubernetes-runner-train-docker-chief-0\t\trunning entrypoint function: criteo_nbdev.trainer.train_and_evaluate_keras_model_small\n",
      "kubernetes-runner-train-docker-chief-0\t\t2020-04-01 23:36:43.936664: I tensorflow_io/core/kernels/cpu_check.cc:127] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "kubernetes-runner-train-docker-chief-0\t\tadditional args: ['--job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir/model_mirrored_strategy_3']\n",
      "kubernetes-runner-train-docker-chief-0\t\t/root/gcp_runner/gcp_runner/entry_point.py:79: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "kubernetes-runner-train-docker-chief-0\t\t  args_spec = inspect.getargspec(func)\n",
      "kubernetes-runner-train-docker-chief-0\t\tArgSpec(args=['distribution_strategy', 'job_dir'], varargs=None, keywords='kwargs', defaults=(None, None))\n",
      "kubernetes-runner-train-docker-chief-0\t\tTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/gcp_runner/gcp_runner/entry_point.py\", line 101, in <module>\n",
      "    main()\n",
      "  File \"/root/gcp_runner/gcp_runner/entry_point.py\", line 88, in main\n",
      "    distribution_strategy_type = DistributionStrategyType(args.distribution_strategy)\n",
      "AttributeError: 'Namespace' object has no attribute 'distribution_strategy'\n",
      "kubernetes-runner-train-docker-chief-0\tError detected in gke_instances\t\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "\u001b[31mNo resources found.\u001b[0m\n",
      "logs since 2020-04-01T23:38:19+00:00\n",
      "kubernetes-runner-train-docker-chief-0\t\tin gcp_runner entry point\n",
      "kubernetes-runner-train-docker-chief-0\t\trunning entrypoint function: criteo_nbdev.trainer.train_and_evaluate_keras_model_small\n",
      "kubernetes-runner-train-docker-chief-0\t\t2020-04-01 23:45:43.027940: I tensorflow_io/core/kernels/cpu_check.cc:127] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "kubernetes-runner-train-docker-chief-0\t\tadditional args: ['--job-dir=gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir/model_mirrored_strategy_3']\n",
      "kubernetes-runner-train-docker-chief-0\t\t/root/gcp_runner/gcp_runner/entry_point.py:79: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "kubernetes-runner-train-docker-chief-0\t\t  args_spec = inspect.getargspec(func)\n",
      "kubernetes-runner-train-docker-chief-0\t\tArgSpec(args=['distribution_strategy', 'job_dir'], varargs=None, keywords='kwargs', defaults=(None, None))\n",
      "kubernetes-runner-train-docker-chief-0\t\tTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/gcp_runner/gcp_runner/entry_point.py\", line 101, in <module>\n",
      "    main()\n",
      "  File \"/root/gcp_runner/gcp_runner/entry_point.py\", line 88, in main\n",
      "    distribution_strategy_type = DistributionStrategyType(args.distribution_strategy)\n",
      "AttributeError: 'Namespace' object has no attribute 'distribution_strategy'\n",
      "logs since 2020-04-01T23:47:34+00:00\n"
     ]
    }
   ],
   "source": [
    "import gcp_runner.kubernetes_runner\n",
    "from gcp_runner import ai_platform_constants\n",
    "\n",
    "gcp_runner.kubernetes_runner.run_docker_image(\n",
    "    some_function_to_run_on_cloud,\n",
    "    'gs://alekseyv-scalableai-dev-criteo-model-bucket/test-job-dir',\n",
    "    image_uri='gcr.io/alekseyv-scalableai-dev/tf2-cpu.2-1',\n",
    "    distribution_strategy_type=ai_platform_constants.DistributionStrategyType.MIRRORED_STRATEGY,\n",
    "    use_distribution_strategy_scope=True,\n",
    "    dry_run=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
