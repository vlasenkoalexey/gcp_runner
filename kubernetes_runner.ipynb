{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp kubernetes_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "import gcp_runner.local_runner\n",
    "import jinja2\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from gcp_runner import ai_platform_constants\n",
    "\n",
    "def _get_not_none(arg, default):\n",
    "    return default if arg is None else arg\n",
    "\n",
    "def run_docker_image(\n",
    "    func, \n",
    "    job_dir,\n",
    "    build_docker_file=None,\n",
    "    dry_run=False,\n",
    "    job_name=None,\n",
    "    region=None,\n",
    "    image_uri=None,\n",
    "    port=5000,\n",
    "    privileged=False,\n",
    "    master_machine_type: ai_platform_constants.MachineType = None,\n",
    "    master_accelerator_count=None,\n",
    "    parameter_machine_type: ai_platform_constants.MachineType = None,\n",
    "    parameter_machine_count=None,\n",
    "    parameter_accelerator_count=None,\n",
    "    worker_machine_type: ai_platform_constants.MachineType = None,\n",
    "    worker_machine_count=None,\n",
    "    work_accelerator_count=None,\n",
    "    tpu_count=None,\n",
    "    distribution_strategy_type: ai_platform_constants.DistributionStrategyType = None,\n",
    "    **kwargs):\n",
    "    \n",
    "    if not image_uri:\n",
    "        raise ValueError('image_uri argument is required')\n",
    "        \n",
    "    if not job_name:\n",
    "        job_name = 'kubernetes-runner-train-docker'\n",
    "        \n",
    "    if build_docker_file is not None:\n",
    "        build_docker_args = ['docker', 'build', '-f', build_docker_file, '-t', image_uri, './']\n",
    "        print('building Docker image:')\n",
    "        print(' '.join(build_docker_args))\n",
    "        if not dry_run:\n",
    "            result = gcp_runner.local_runner.run_process(build_docker_args)\n",
    "            if result:\n",
    "                return result\n",
    "        push_docker_args = ['docker', 'push', image_uri]\n",
    "        print('pushing Docker image:')\n",
    "        print(' '.join(push_docker_args))\n",
    "        if not dry_run:\n",
    "            result = gcp_runner.local_runner.run_process(push_docker_args)\n",
    "            if result:\n",
    "                return result\n",
    "\n",
    "    master_machine_count = 1\n",
    "    if distribution_strategy_type == ai_platform_constants.DistributionStrategyType.MIRRORED_STRATEGY:\n",
    "        master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.CENTRAL_STORAGE_STRATEGY:\n",
    "        master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.PARAMETER_SERVERSTRATEGY:\n",
    "        parameter_machine_count = _get_not_none(parameter_machine_count, 1)\n",
    "        worker_machine_count = _get_not_none(worker_machine_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.MULTI_WORKER_MIRRORED_STRATEGY:\n",
    "        master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "        work_accelerator_count = _get_not_none(work_accelerator_count, 2)\n",
    "        worker_machine_count = _get_not_none(worker_machine_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.TPU_STRATEGY:\n",
    "        # minimal available number for central1-c  # https://cloud.google.com/tpu/docs/types-zones\n",
    "        tpu_count = _get_not_none(tpu_count, 8)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.ONE_DEVICE_STRATEGY:\n",
    "        pass\n",
    "    \n",
    "    master_machine_type = _get_not_none(master_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    worker_machine_type = _get_not_none(worker_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    parameter_machine_type = _get_not_none(parameter_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    \n",
    "    master_accelerator_count = _get_not_none(master_accelerator_count, 0)\n",
    "    work_accelerator_count = _get_not_none(work_accelerator_count, 0)\n",
    "    parameter_accelerator_count = _get_not_none(parameter_accelerator_count, 0)\n",
    "\n",
    "    parameter_machine_count = _get_not_none(parameter_machine_count, 0)\n",
    "    worker_machine_count = _get_not_none(worker_machine_count, 0)\n",
    "    tpu_count = _get_not_none(tpu_count, 0)\n",
    "        \n",
    "    #TODO: map machine_type to memory and cpu availability, and pass them to template\n",
    "    \n",
    "    run_python_args = gcp_runner.local_runner._get_run_python_args(func, **kwargs)\n",
    "    run_python_args.append(\"--job-dir=%s\" % job_dir)\n",
    "    if distribution_strategy_type is not None:\n",
    "        run_python_args.append(\"--distribution-strategy-type=%s\" % distribution_strategy_type)\n",
    "\n",
    "    #TODO: properly pass args to python\n",
    "    yaml = None\n",
    "    with open(\"template.yaml.jinja\", \"r\") as f:\n",
    "        print('Generating kubernetes YAML file:')\n",
    "        yaml = (jinja2.Template(f.read()).render(\n",
    "            name=job_name,\n",
    "            image_uri=image_uri,\n",
    "            port=port,\n",
    "            privileged=privileged,\n",
    "            master_machine_count=master_machine_count,\n",
    "            parameter_machine_count=parameter_machine_count,\n",
    "            worker_machine_count=worker_machine_count,\n",
    "            master_accelerator_count=master_accelerator_count,\n",
    "            parameter_accelerator_count=parameter_accelerator_count,\n",
    "            work_accelerator_count=work_accelerator_count,\n",
    "            tpu_count=tpu_count,\n",
    "            train_dir=job_dir,\n",
    "            cmdline_args=run_python_args))\n",
    "    if yaml is None:\n",
    "        return -1\n",
    "    print(yaml)\n",
    "    \n",
    "    print('Deleting all resources on Kubernetes cluster:')\n",
    "    #command = 'kubectl delete pod,service,PodSecurityPolicy --all'\n",
    "    command = 'kubectl delete namespace kubernetes-runner-namespace'\n",
    "    print(command)\n",
    "    gcp_runner.local_runner.run_process(command.split(' '))\n",
    "    \n",
    "    fd, path = tempfile.mkstemp()\n",
    "    try:\n",
    "        with os.fdopen(fd, 'w') as tmp:\n",
    "            # do stuff with temp file\n",
    "            tmp.write(yaml)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Creating Kubernetes kubernetes-runner-namespace namespace:')\n",
    "    #args = ['kubectl', 'delete', 'pod,service,PodSecurityPolicy', '--all']\n",
    "    command = 'kubectl create namespace kubernetes-runner-namespace'\n",
    "    print(command)\n",
    "    gcp_runner.local_runner.run_process(command.split(' '))\n",
    "        \n",
    "    print('Creating Kubernetes cluster:')\n",
    "    command = 'kubectl create -f %s --namespace=kubernetes-runner-namespace' % path\n",
    "    print(command)\n",
    "    result = gcp_runner.local_runner.run_process(command.split(' '))\n",
    "    if result:\n",
    "        return result\n",
    "    \n",
    "    print('Polling Kubernetes logs:')\n",
    "    gcp_runner.local_runner.run_process(['./poll_kubernetes_logs.sh'])    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitc34665d47f6a46efaf2c998849165367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
