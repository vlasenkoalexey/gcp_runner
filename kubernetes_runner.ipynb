{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp kubernetes_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "import jinja2\n",
    "import errno\n",
    "import os\n",
    "import os.path\n",
    "import tempfile\n",
    "import gcp_runner.core\n",
    "\n",
    "from gcp_runner import ai_platform_constants\n",
    "from gcp_runner.core import build_and_push_docker_image, run_process, get_run_python_args\n",
    "\n",
    "def _get_not_none(arg, default):\n",
    "    return default if arg is None else arg\n",
    "\n",
    "def _find_project_file(file_name):\n",
    "    searched_dirs = []\n",
    "    # Look in current directory when running from notebook\n",
    "    template_path = os.path.join(os.getcwd(), file_name)\n",
    "    if os.path.isfile(template_path):\n",
    "        return template_path\n",
    "    searched_dirs.append(template_path)\n",
    "    \n",
    "    # Look in package directory when running pip installed package\n",
    "    template_path = os.path.join(os.path.dirname(gcp_runner.core.__file__), file_name)\n",
    "    if os.path.isfile(template_path):\n",
    "        return template_path\n",
    "    searched_dirs.append(template_path)\n",
    "\n",
    "    # Look in package parent directory when running editable pip installed package\n",
    "    template_path = os.path.join(os.path.dirname(os.path.dirname(gcp_runner.core.__file__)), file_name)\n",
    "    if os.path.isfile(template_path):\n",
    "        return template_path\n",
    "    searched_dirs.append(template_path)\n",
    "    error_message = 'niether %s can be found' % searched_dirs.join(',')\n",
    "    raise FileNotFoundError(\n",
    "        errno.ENOENT, error_message, file_name)\n",
    "        \n",
    "def run_docker_image(\n",
    "    func, \n",
    "    job_dir,\n",
    "    image_uri,\n",
    "    build_docker_file=None,\n",
    "    dry_run=False,\n",
    "    job_name=None,\n",
    "    region=None,\n",
    "    port=5000,\n",
    "    privileged=False,\n",
    "    master_machine_type: ai_platform_constants.MachineType = None,\n",
    "    master_accelerator_count=None,\n",
    "    parameter_machine_type: ai_platform_constants.MachineType = None,\n",
    "    parameter_machine_count=None,\n",
    "    parameter_accelerator_count=None,\n",
    "    worker_machine_type: ai_platform_constants.MachineType = None,\n",
    "    worker_machine_count=None,\n",
    "    work_accelerator_count=None,\n",
    "    tpu_count=None,\n",
    "    distribution_strategy_type: ai_platform_constants.DistributionStrategyType = None,\n",
    "    **kwargs):\n",
    "    \n",
    "    if not image_uri:\n",
    "        raise ValueError('image_uri argument is required')\n",
    "        \n",
    "    if not job_name:\n",
    "        job_name = 'kubernetes-runner-train-docker'\n",
    "        \n",
    "    if build_docker_file is not None:\n",
    "        result = build_and_push_docker_image(build_docker_file, image_uri, dry_run=dry_run)\n",
    "        if result:\n",
    "            return result\n",
    "\n",
    "    master_machine_count = 1\n",
    "    if distribution_strategy_type == ai_platform_constants.DistributionStrategyType.MIRRORED_STRATEGY:\n",
    "        master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.CENTRAL_STORAGE_STRATEGY:\n",
    "        master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.PARAMETER_SERVERSTRATEGY:\n",
    "        parameter_machine_count = _get_not_none(parameter_machine_count, 1)\n",
    "        worker_machine_count = _get_not_none(worker_machine_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.MULTI_WORKER_MIRRORED_STRATEGY:\n",
    "        master_accelerator_count = _get_not_none(master_accelerator_count, 2)\n",
    "        work_accelerator_count = _get_not_none(work_accelerator_count, 2)\n",
    "        worker_machine_count = _get_not_none(worker_machine_count, 2)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.TPU_STRATEGY:\n",
    "        # minimal available number for central1-c  # https://cloud.google.com/tpu/docs/types-zones\n",
    "        tpu_count = _get_not_none(tpu_count, 8)\n",
    "    elif distribution_strategy_type == ai_platform_constants.DistributionStrategyType.ONE_DEVICE_STRATEGY:\n",
    "        pass\n",
    "    \n",
    "    master_machine_type = _get_not_none(master_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    worker_machine_type = _get_not_none(worker_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    parameter_machine_type = _get_not_none(parameter_machine_type, ai_platform_constants.MachineType.N1_STANDARD_4)\n",
    "    \n",
    "    master_accelerator_count = _get_not_none(master_accelerator_count, 0)\n",
    "    work_accelerator_count = _get_not_none(work_accelerator_count, 0)\n",
    "    parameter_accelerator_count = _get_not_none(parameter_accelerator_count, 0)\n",
    "\n",
    "    parameter_machine_count = _get_not_none(parameter_machine_count, 0)\n",
    "    worker_machine_count = _get_not_none(worker_machine_count, 0)\n",
    "    tpu_count = _get_not_none(tpu_count, 0)\n",
    "        \n",
    "    #TODO: map machine_type to memory and cpu availability, and pass them to template\n",
    "    \n",
    "    run_python_args = get_run_python_args(func, **kwargs)\n",
    "    run_python_args.append(\"--job-dir=%s\" % job_dir)\n",
    "    if distribution_strategy_type is not None:\n",
    "        run_python_args.append(\"--distribution-strategy-type=%s\" % distribution_strategy_type)\n",
    "\n",
    "    #TODO: properly pass args to python\n",
    "    yaml = None\n",
    "    with open(_find_project_file(\"template.yaml.jinja\"), \"r\") as f:\n",
    "        print('Generating kubernetes YAML file:')\n",
    "        yaml = (jinja2.Template(f.read()).render(\n",
    "            name=job_name,\n",
    "            image_uri=image_uri,\n",
    "            port=port,\n",
    "            privileged=privileged,\n",
    "            master_machine_count=master_machine_count,\n",
    "            parameter_machine_count=parameter_machine_count,\n",
    "            worker_machine_count=worker_machine_count,\n",
    "            master_accelerator_count=master_accelerator_count,\n",
    "            parameter_accelerator_count=parameter_accelerator_count,\n",
    "            work_accelerator_count=work_accelerator_count,\n",
    "            tpu_count=tpu_count,\n",
    "            train_dir=job_dir,\n",
    "            cmdline_args=run_python_args))\n",
    "    if yaml is None:\n",
    "        return -1\n",
    "    print(yaml.replace('\\n\\n','\\n'))\n",
    "    \n",
    "    print('Deleting all resources on Kubernetes cluster:')\n",
    "    #command = 'kubectl delete pod,service,PodSecurityPolicy --all'\n",
    "    command = 'kubectl delete namespace kubernetes-runner-namespace'\n",
    "    print(command)\n",
    "    run_process(command.split(' '))\n",
    "    \n",
    "    fd, path = tempfile.mkstemp()\n",
    "    try:\n",
    "        with os.fdopen(fd, 'w') as tmp:\n",
    "            # do stuff with temp file\n",
    "            tmp.write(yaml)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Creating Kubernetes kubernetes-runner-namespace namespace:')\n",
    "    #args = ['kubectl', 'delete', 'pod,service,PodSecurityPolicy', '--all']\n",
    "    command = 'kubectl create namespace kubernetes-runner-namespace'\n",
    "    print(command)\n",
    "    run_process(command.split(' '))\n",
    "        \n",
    "    print('Creating Kubernetes cluster:')\n",
    "    command = 'kubectl create -f %s --namespace=kubernetes-runner-namespace' % path\n",
    "    print(command)\n",
    "    result = run_process(command.split(' '))\n",
    "    if result:\n",
    "        return result\n",
    "    \n",
    "    print('Polling Kubernetes logs:')\n",
    "    run_process([_find_project_file('poll_kubernetes_logs.sh')])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
